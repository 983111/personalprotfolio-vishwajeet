<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Vishwajeet Adkine — Research CV</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=EB+Garamond:ital,wght@0,400;0,500;0,600;1,400&family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <style>
        :root {
            --bg: #fafafa;
            --card: #ffffff;
            --ink: #111827;
            --muted: #6b7280;
            --accent: #1d4ed8;
            --accent-light: #eff6ff;
            --border: #e5e7eb;
            --rule: #d1d5db;
            --green: #065f46;
            --green-bg: #ecfdf5;
        }
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body {
            font-family: 'Inter', sans-serif;
            background: var(--bg);
            color: var(--ink);
            line-height: 1.65;
            font-size: 14px;
        }

        .page {
            max-width: 860px;
            margin: 32px auto;
            background: var(--card);
            padding: 3rem 3.4rem;
            box-shadow: 0 2px 16px rgba(0,0,0,0.06);
            border: 1px solid var(--border);
        }

        /* HEADER */
        .header { margin-bottom: 1.8rem; border-bottom: 2px solid var(--ink); padding-bottom: 1rem; }
        .header h1 {
            font-family: 'EB Garamond', serif;
            font-size: 2.4rem;
            font-weight: 600;
            letter-spacing: -0.01em;
            color: var(--ink);
            margin-bottom: 0.3rem;
        }
        .header .tagline {
            font-size: 0.88rem;
            color: var(--muted);
            font-weight: 500;
            margin-bottom: 0.45rem;
        }
        .header .contacts {
            font-size: 0.83rem;
            color: var(--muted);
        }
        .header .contacts a { color: var(--accent); text-decoration: none; }
        .header .contacts a:hover { text-decoration: underline; }

        /* SECTION */
        h2 {
            font-family: 'Inter', sans-serif;
            font-size: 0.72rem;
            font-weight: 700;
            text-transform: uppercase;
            letter-spacing: 0.1em;
            color: var(--accent);
            border-bottom: 1px solid var(--rule);
            padding-bottom: 0.25rem;
            margin: 1.8rem 0 0.85rem;
        }

        /* ENTRY */
        .entry { margin-bottom: 1.3rem; }
        .entry-head { display: flex; justify-content: space-between; align-items: baseline; gap: 1rem; flex-wrap: wrap; }
        .entry-title { font-weight: 700; font-size: 0.95rem; }
        .entry-sub { font-size: 0.85rem; color: var(--muted); }
        .entry-date { font-size: 0.8rem; color: var(--muted); white-space: nowrap; font-style: italic; }

        /* BULLETS */
        ul.bl { list-style: none; margin-top: 0.4rem; }
        ul.bl li {
            position: relative;
            padding-left: 1.1rem;
            margin-bottom: 0.28rem;
            font-size: 0.88rem;
            color: #1f2937;
        }
        ul.bl li::before { content: '—'; color: var(--muted); position: absolute; left: 0; }

        /* RESEARCH QUESTION CALLOUT */
        .rq {
            background: var(--accent-light);
            border-left: 3px solid var(--accent);
            padding: 0.5rem 0.85rem;
            margin: 0.5rem 0;
            font-size: 0.85rem;
            border-radius: 0 4px 4px 0;
        }
        .rq strong { color: var(--accent); }

        /* PAPER ITEM */
        .paper { margin-bottom: 1.1rem; padding-left: 1rem; border-left: 2px solid var(--rule); }
        .paper-title { font-size: 0.9rem; font-weight: 600; font-style: italic; }
        .paper-meta { font-size: 0.8rem; color: var(--muted); margin-top: 0.1rem; }
        .paper-status {
            display: inline-block;
            font-size: 0.72rem;
            font-weight: 700;
            padding: 0.1rem 0.45rem;
            border-radius: 3px;
            margin-left: 0.4rem;
            background: #fef3c7;
            color: #92400e;
        }
        .paper-status.pr { background: var(--green-bg); color: var(--green); }

        /* METRICS TABLE */
        .mt-wrap { overflow-x: auto; margin: 0.6rem 0; }
        table.m {
            width: 100%;
            border-collapse: collapse;
            font-size: 0.82rem;
        }
        table.m th {
            background: #f1f5f9;
            color: var(--ink);
            padding: 0.32rem 0.65rem;
            border: 1px solid var(--border);
            text-align: left;
            font-weight: 600;
        }
        table.m td { padding: 0.28rem 0.65rem; border: 1px solid var(--border); }
        table.m tr:nth-child(even) td { background: #fafafa; }
        .hi { font-weight: 700; color: var(--green); }

        /* TAGS */
        .tags { margin: 0.4rem 0; }
        .tag {
            display: inline-block;
            background: var(--accent-light);
            color: var(--accent);
            padding: 0.14rem 0.46rem;
            border-radius: 3px;
            font-size: 0.74rem;
            font-weight: 600;
            margin: 0.07rem;
        }
        .tag.g { background: var(--green-bg); color: var(--green); }

        /* SKILLS */
        .skills-row { display: flex; flex-wrap: wrap; gap: 0.35rem; margin-top: 0.45rem; }
        .st {
            background: #f1f5f9;
            color: var(--ink);
            padding: 0.18rem 0.5rem;
            border-radius: 3px;
            font-size: 0.8rem;
        }

        /* AWARDS TABLE */
        table.aw { width: 100%; font-size: 0.87rem; border-collapse: collapse; }
        table.aw td { padding: 0.28rem 0.5rem; vertical-align: top; }
        table.aw td:first-child { font-weight: 600; white-space: nowrap; padding-right: 1.2rem; }
        table.aw td:last-child { color: var(--muted); font-size: 0.82rem; }

        /* GITHUB LINK */
        .gh { font-size: 0.8rem; color: var(--accent); font-weight: 600; margin-top: 0.3rem; display: inline-block; }
        .gh::before { content: '↗ '; }

        @media (max-width: 640px) {
            .page { padding: 1.5rem; }
            .header h1 { font-size: 1.8rem; }
        }
    </style>
</head>
<body>
<div class="page">

    <!-- ── HEADER ── -->
    <div class="header">
        <h1>Vishwajeet Shashikant Adkine</h1>
        <div class="tagline">Independent AI Researcher &nbsp;·&nbsp; High School Student &nbsp;·&nbsp; India</div>
        <div class="contacts">
            <a href="mailto:vishwajeetadkine705@gmail.com">vishwajeetadkine705@gmail.com</a>
            &nbsp;·&nbsp; <a href="https://personalprotfolio-vishwajeet-kh8z.vercel.app/">Portfolio</a>
            &nbsp;·&nbsp; <a href="https://vishwajeetadkine.blogspot.com/">Research Blog</a>
            &nbsp;·&nbsp; GitHub: <a href="#">github.com/vishwajeet-adkine</a>
        </div>
    </div>

    <!-- ── RESEARCH INTERESTS ── -->
    <h2>Research Interests</h2>
    <p style="font-size:0.88rem; color:#374151; line-height:1.7;">
        Theoretical foundations of deep learning — particularly <strong>optimisation dynamics</strong>, <strong>spectral properties of neural operators</strong>, and <strong>AI safety &amp; reliability</strong>. I study how and why gradient-based learning converges or fails, how attention mechanisms organise information spectrally, and how interpretable ML pipelines can be made robust against adversarial misuse (scam detection, prompt injection). Long-term interest: understanding generalisation through the lens of dynamical systems.
    </p>

    <!-- ── EDUCATION ── -->
    <h2>Education</h2>
    <div class="entry">
        <div class="entry-head">
            <div>
                <div class="entry-title">Gokulnath Higher Secondary School</div>
                <div class="entry-sub">Class 12 (expected) — Mathematics, Physics, Computer Science</div>
            </div>
            <div class="entry-date">2024–2025</div>
        </div>
        <ul class="bl">
            <li>Class 12 projected: 94–98% (predicted school topper) &nbsp;·&nbsp; Class 11: 93.17% (school topper)</li>
        </ul>
    </div>

    <!-- ── RESEARCH MANUSCRIPTS ── -->
    <h2>Research Manuscripts &amp; Preprints</h2>

    <div class="paper">
        <div class="paper-title">"Gradient Descent as a Dynamical System: Stability, Phase Transitions, and Convergence" <span class="paper-status">Independent Manuscript</span></div>
        <div class="paper-meta">Vishwajeet Adkine &nbsp;·&nbsp; 2025 &nbsp;·&nbsp; <a href="#" style="color:var(--accent);font-size:0.8rem;">PDF ↗</a></div>
        <div class="rq"><strong>Research Question:</strong> Under what conditions does gradient descent on a smooth loss behave as a stable fixed-point iteration, and how does learning rate determine qualitative phase-transition behaviour?</div>
        <ul class="bl">
            <li>Framed update rule as discrete-time map Φ_η; proved fixed points are exactly stationary points of L, independent of η.</li>
            <li>Derived Theorem 1: local stability iff ρ(I − ηH) &lt; 1; derived optimal η* = 2/(λ_min + λ_max) minimising ρ to (κ−1)/(κ+1).</li>
            <li>Characterised three dynamical regimes — geometric convergence, critical oscillation, explosive divergence — with bifurcation analysis.</li>
            <li>Convergence bound: ‖θ_t − θ*‖ ≤ ρ^t · ‖θ_0 − θ*‖; sample complexity T(ε) = O(κ · log 1/ε).</li>
            <li>Discussed momentum as complex-eigenvalue rotation achieving O(√κ) convergence improvement.</li>
            <li>Accompanied by open-source interactive visualisation (4 live Canvas figures: trajectory, bifurcation, theory-vs-empirical, eigenvalue explorer).</li>
        </ul>
    </div>

    <div class="paper">
        <div class="paper-title">"Spectral Properties of Attention Matrices: Eigenvalue Concentration, Singular Value Decay, Norm Scaling, and Expressivity Bounds" <span class="paper-status">Independent Manuscript</span></div>
        <div class="paper-meta">Vishwajeet Adkine &nbsp;·&nbsp; 2025 &nbsp;·&nbsp; <a href="#" style="color:var(--accent);font-size:0.8rem;">PDF ↗</a></div>
        <div class="rq"><strong>Research Question:</strong> How does the spectral structure of softmax attention matrices evolve during training, and what does it imply for expressivity, stability, and sparsity in transformers?</div>
        <ul class="bl">
            <li>Proved eigenvalue concentration: training dynamics drive λᵢ(t) toward dominant real components; full spectrum lies within unit disk (row-stochastic property).</li>
            <li>Established power-law singular decay σᵢ ≈ C/i^α, α ∈ [0.5, 1.0]; effective rank r_eff = O(n^{(2α−1)/α}) collapses to O(√n) in deep layers.</li>
            <li>Stability Theorem: softmax normalisation guarantees ‖A‖_F = O(√n) and ‖A‖_spec = O(log n) — theoretical basis for long-context numerical stability.</li>
            <li>Formalised sparsity–expressivity duality: effective rank ≈ exp(H(attention)); derived practical sparsity guidelines.</li>
            <li>Accompanied by open-source interactive visualisation (5 live figures: eigenvalue evolution, log-log singular decay, norm scaling, sparsity explorer, expressivity surface).</li>
        </ul>
    </div>

    <div class="paper">
        <div class="paper-title">"An Interpretable Multi-Signal Scam Detection System Using Machine Learning and Large Language Models" <span class="paper-status pr">Published — Blog / Preprint</span></div>
        <div class="paper-meta">Vishwajeet Adkine &nbsp;·&nbsp; Feb 2025 &nbsp;·&nbsp; <a href="https://vishwajeetadkine.blogspot.com/" style="color:var(--accent);font-size:0.8rem;">Read ↗</a></div>
        <div class="rq"><strong>Research Question:</strong> Can a lightweight interpretable ML pipeline match LLM-scale accuracy for scam detection while being cost-efficient enough for real-time mobile deployment?</div>
        <ul class="bl">
            <li><strong>Dataset:</strong> ~28,000 URLs (50% malicious from URLhaus, 50% benign from Tranco Top 1M); 1,000 text samples (60/40 scam/safe) via structured template synthesis.</li>
            <li><strong>Features:</strong> 16 hand-engineered signals — urgency keywords, money terms, sensitive info requests, URL shorteners, risky TLDs, domain spoofing, verified domains, capped heuristic score.</li>
            <li><strong>Models:</strong> Logistic Regression with L2 + 5-fold Platt calibration (text); Random Forest (URL); ensemble with cost-gated LLM fallback.</li>
            <li><strong>Results:</strong> Scam recall 1.00, scam F1 0.97, ROC-AUC ~0.99, 5-fold CV ~0.97 ± 0.02, URL accuracy 99.96%, inference &lt;5ms.</li>
            <li><strong>Cost efficiency:</strong> LLM invoked only for confidence ∈ [0.4, 0.6] — ~90% API cost reduction; fully documented bias analysis and weekly retraining pipeline.</li>
            <li>Evaluation produces 9 reproducibility figures (confusion matrix, ROC, PR, calibration curve, feature importances, threshold sweep).</li>
        </ul>
    </div>

    <div class="paper">
        <div class="paper-title">Additional Research Notes</div>
        <ul class="bl" style="margin-top:0.35rem;">
            <li>Self-Verification Prompting for Reliable Chatbots — two-step hallucination reduction protocol.</li>
            <li>Prompt Injection Defense via Context Sanitisation — semantic filters for jailbreak prevention.</li>
            <li>Improving Temporal Awareness in LLMs — real-time prompt-grounding via API injection.</li>
        </ul>
    </div>

    <!-- ── FROM-SCRATCH IMPLEMENTATION ── -->
    <h2>Technical Research Implementation</h2>

    <div class="entry">
        <div class="entry-head">
            <div>
                <div class="entry-title">Character-Level LSTM — Pure NumPy, From Scratch</div>
                <div class="entry-sub">Study in gradient dynamics and numerical optimisation</div>
            </div>
            <div class="entry-date">2024</div>
        </div>
        <div class="rq"><strong>Research Question:</strong> Can manually implementing BPTT and Adam in raw NumPy — without any framework — expose failure modes in gradient flow that abstracted libraries conceal?</div>
        <ul class="bl">
            <li>Built LSTM forward and backward pass, embedding layer, and linear decoder entirely in NumPy; no PyTorch, TensorFlow, or autograd.</li>
            <li>Manual BPTT engine with Adam optimiser; gradient clipping (threshold 5.0) and Xavier initialisation to observe and mitigate vanishing/exploding gradients directly.</li>
            <li>Training loss: 3.258 → 0.076 (~97.6% reduction) over 300 epochs; text generation via temperature-controlled sampling.</li>
            <li>Implementation served as empirical testbed for gradient dynamics studied in the dynamical systems manuscript above.</li>
        </ul>
        <a href="#" class="gh">github.com/vishwajeet-adkine/lstm-numpy</a>
    </div>

    <!-- ── APPLIED RESEARCH PROJECTS ── -->
    <h2>Applied Research Projects</h2>

    <div class="entry">
        <div class="entry-head">
            <div>
                <div class="entry-title">Stremini AI — AI Reliability &amp; Safety System</div>
                <div class="entry-sub">Scam detection, agentic code repair, LLM safety pipelines</div>
            </div>
        </div>
        <ul class="bl">
            <li>Deterministic code-generation agent with "Read-Fix-Verify" autonomous remediation — designed around failure-mode analysis, not just capability.</li>
            <li>Multi-signal scam detection engine (text + URL + image) with WHOIS and Safe Browsing API; real-world deployment of paper above.</li>
            <li>Context-aware LLM keyboard with heuristic preprocessing and hallucination mitigation; serverless inference via Cloudflare Workers.</li>
        </ul>
    </div>

    <div class="entry">
        <div class="entry-head">
            <div>
                <div class="entry-title">Scholira — Hallucination-Free Retrieval System</div>
                <div class="entry-sub">AI Scholarship Finder · TF-IDF + rule-based (no generative hallucination)</div>
            </div>
        </div>
        <ul class="bl">
            <li>Deliberate choice of non-generative retrieval (TF-IDF + deterministic rules) to guarantee 100% factual accuracy in scholarship eligibility matching — a case study in knowing when not to use LLMs.</li>
        </ul>
    </div>

    <div class="entry">
        <div class="entry-head">
            <div>
                <div class="entry-title">KhetiAI / FinPlanAgent / Styfi</div>
                <div class="entry-sub">Agricultural AI · Financial Advisory · Fashion Vision</div>
            </div>
        </div>
        <ul class="bl">
            <li>Multi-modal generative pipelines with strict JSON schema enforcement, exponential backoff fault tolerance, and LLM output sanitisation for clean explainability.</li>
            <li>FinPlanAgent: "What-if" financial simulation with TF-IDF anomaly detection and reasoning trace suppression for XAI compliance.</li>
        </ul>
    </div>

    <!-- ── HONOURS ── -->
    <h2>Honors &amp; Awards</h2>
    <table class="aw">
        <tr><td>National Rank 14</td><td>SCO Mathematics Olympiad</td></tr>
        <tr><td>Certificate of Excellence + LOR</td><td>IMUN Mathematics Olympiad</td></tr>
        <tr><td>Top International Rank</td><td>School Connect AI Olympiad</td></tr>
    </table>

    <!-- ── CERTIFICATIONS ── -->
    <h2>Certifications</h2>
    <ul class="bl">
        <li><strong>Machine Learning Specialisation</strong> — Stanford University / DeepLearning.AI (Andrew Ng)</li>
        <li><strong>Python for Everybody</strong> — University of Michigan</li>
        <li><strong>Prompt Engineering for Developers</strong> — DeepLearning.AI</li>
    </ul>

    <!-- ── TECHNICAL SKILLS ── -->
    <h2>Technical Skills</h2>
    <div class="skills-row">
        <span class="st">Python</span>
        <span class="st">NumPy</span>
        <span class="st">Logistic Regression</span>
        <span class="st">Random Forest</span>
        <span class="st">LSTM (from scratch)</span>
        <span class="st">Feature Engineering</span>
        <span class="st">NLP / TF-IDF</span>
        <span class="st">RAG</span>
        <span class="st">LLM Orchestration</span>
        <span class="st">Agentic Systems</span>
        <span class="st">Prompt Engineering</span>
        <span class="st">Flask / FastAPI</span>
        <span class="st">JavaScript</span>
        <span class="st">Dart / Flutter</span>
        <span class="st">Kotlin</span>
        <span class="st">Cloudflare Workers</span>
        <span class="st">React / TypeScript</span>
        <span class="st">C++</span>
        <span class="st">Git</span>
        <span class="st">Firebase</span>
    </div>

    <!-- ── REFERENCES ── -->
    <h2>References</h2>
    <p style="font-size:0.87rem; color:var(--muted);">Available upon request.</p>

</div>
</body>
</html>
